> Loaded logger: ./results/full.log
> Setup PyTorch: seed(1), cuda(None)

[--- LOAD DATA -> (['train', 'eval']) ---]
> Load/Init from ./data/tweets.train.csv
> Load/Init from ./data/tweets.eval.csv

[--- LOAD COMPONENTS ---]
> Init Encoder: 'bert-base-uncased'
> f(__init__) took: 8.1725 sec
> Init BERT-Head (MLP), trainable parameters: 197635

[--- TRAIN -> ./data/tweets.train.csv ---]
> Warning: Training interrupted by user!
> Load best model based on evaluation loss.
